{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "054230eb",
   "metadata": {},
   "source": [
    "# Hotspot Storytelling Notebook\n",
    "\n",
    "This notebook packages the existing medallion outputs (L2 → L3) into a set of quick hotspot visuals.\n",
    "\n",
    "**What you get**\n",
    "- Daily incident trends for a selected month\n",
    "- H3 hex hotspot map (resolutions 8/9) using deterministic L3 aggregates\n",
    "- Optional HDBSCAN cluster overlay using the clustering prototype\n",
    "\n",
    "> Tip: run this from the repository root so relative paths resolve (e.g. `jupyter lab`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3ebcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import h3\n",
    "import sys\n",
    "\n",
    "ROOT = Path.cwd().resolve()\n",
    "SRC_DIR = ROOT / 'src'\n",
    "if str(SRC_DIR) not in sys.path:\n",
    "    sys.path.insert(0, str(SRC_DIR))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd7c575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "YEAR = 2024\n",
    "MONTH = 9\n",
    "H3_RES = 9  # default to street-level view\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d16403",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_l3_partition(year: int, month: int, res: int) -> pd.DataFrame:\n",
    "    path = ROOT / f'data/l3/res={res}/year={year}/month={month:02d}' / f'l3-aggregates-{res}-{year}-{month:02d}.parquet'\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f'Missing L3 partition: {path}')\n",
    "    df = pd.read_parquet(path)\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    return df\n",
    "\n",
    "\n",
    "l3_df = load_l3_partition(YEAR, MONTH, H3_RES)\n",
    "print(f'L3 rows: {len(l3_df):,}, columns: {list(l3_df.columns)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc52757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daily trend (incident counts)\n",
    "daily = l3_df.groupby('date', as_index=False)['n_crimes'].sum()\n",
    "fig = px.line(daily, x='date', y='n_crimes', title=f'Daily incidents – {YEAR}-{MONTH:02d}', markers=True)\n",
    "fig.update_layout(yaxis_title='Incidents', xaxis_title='Date')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6f9169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate to monthly hotspot summary per H3 cell\n",
    "summary_cols = ['n_crimes', 'n_arrests', 'low_conf', 'smoothed_rate', 'pooled_smoothed']\n",
    "month_summary = (\n",
    "    l3_df.assign(low_conf=lambda d: d['low_conf'].astype(bool))\n",
    "         .groupby(f'h3_r{H3_RES}', dropna=True)[summary_cols]\n",
    "         .agg({\n",
    "             'n_crimes': 'sum',\n",
    "             'n_arrests': 'sum',\n",
    "             'low_conf': 'mean',\n",
    "             'smoothed_rate': 'mean',\n",
    "             'pooled_smoothed': 'mean'\n",
    "         })\n",
    "         .reset_index()\n",
    ")\n",
    "month_summary.rename(columns={f'h3_r{H3_RES}': 'h3_id', 'low_conf': 'low_conf_share'}, inplace=True)\n",
    "month_summary['low_conf_share'] = month_summary['low_conf_share'].round(3)\n",
    "month_summary.sort_values('n_crimes', ascending=False).head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c083f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert H3 hexes to lat/lon centers for plotting\n",
    "month_summary['lat'] = month_summary['h3_id'].apply(lambda h: h3.cell_to_latlng(h)[0])\n",
    "month_summary['lon'] = month_summary['h3_id'].apply(lambda h: h3.cell_to_latlng(h)[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5267228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter map of hotspots (size by incidents, color by smoothed arrest rate)\n",
    "fig = px.scatter_geo(\n",
    "    month_summary,\n",
    "    lat='lat',\n",
    "    lon='lon',\n",
    "    size='n_crimes',\n",
    "    color='smoothed_rate',\n",
    "    hover_data=['h3_id', 'n_crimes', 'n_arrests', 'low_conf_share', 'pooled_smoothed'],\n",
    "    title=f'H3 hotspots (res={H3_RES}) – size=count, color=smoothed arrest rate',\n",
    "    projection='natural earth'\n",
    ")\n",
    "fig.update_layout(height=600)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5c7e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: run clustering prototype and compare\n",
    "from importlib import import_module\n",
    "clustering = import_module('l3_clustering_prototype')\n",
    "clusters_dir = ROOT / 'data' / 'l3' / 'clusters' / f'res={H3_RES}' / f'year={YEAR}' / f'month={MONTH:02d}'\n",
    "clusters_dir.mkdir(parents=True, exist_ok=True)\n",
    "cluster_path = clusters_dir / f'clusters-{H3_RES}-{YEAR}-{MONTH:02d}.parquet'\n",
    "\n",
    "if not cluster_path.exists():\n",
    "    print('Running clustering prototype (UMAP + HDBSCAN)...')\n",
    "    clustering.run_clustering(YEAR, MONTH, res=H3_RES)\n",
    "else:\n",
    "    print('Cluster parquet already exists – reusing cached results.')\n",
    "\n",
    "if cluster_path.exists():\n",
    "    cluster_df = pd.read_parquet(cluster_path)\n",
    "    print(cluster_df.head())\n",
    "    month_summary = month_summary.merge(cluster_df[[f'h3_r{H3_RES}', 'cluster']].rename(columns={f'h3_r{H3_RES}': 'h3_id'}), on='h3_id', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe46ffb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'cluster' in month_summary.columns:\n",
    "    cluster_counts = (\n",
    "        month_summary.groupby('cluster', dropna=False)['n_crimes']\n",
    "        .sum()\n",
    "        .reset_index()\n",
    "        .sort_values('n_crimes', ascending=False)\n",
    "    )\n",
    "    cluster_counts.head(10)\n",
    "else:\n",
    "    print('No clusters available (prototype may have failed to install dependencies).')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf34e443",
   "metadata": {},
   "source": [
    "## Next Steps Checklist\n",
    "- Adjust `YEAR`, `MONTH`, `H3_RES` at the top to explore other periods.\n",
    "- Capture insights (stable hotspots, emerging hexes, low-confidence pockets).\n",
    "- Feed these visuals into the Streamlit app for the two-day demo.\n",
    "\n",
    "If clustering fails, ensure `umap-learn` and `hdbscan` are installed (`pip install umap-learn hdbscan`)."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
